import streamlit as st
import pandas as pd
import numpy as np
import unicodedata
import difflib
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestNeighbors
import warnings

# UyarÄ±larÄ± kapat
warnings.filterwarnings('ignore')

# -----------------------------------------------------------------------------
# 1. SAYFA VE TEMA AYARLARI (KIRMIZI KONSEPT)
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="AI Scout - KÄ±rmÄ±zÄ±",
    page_icon="âš½",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ã–zel CSS ile KÄ±rmÄ±zÄ±/Siyah Tema Entegrasyonu
st.markdown("""
    <style>
    /* Ana Arka Plan */
    .stApp {
        background-color: #121212;
        color: #e0e0e0;
    }
    /* BaÅŸlÄ±klar */
    h1, h2, h3 {
        color: #ff4b4b !important; /* Streamlit KÄ±rmÄ±zÄ±sÄ± */
        font-family: 'Helvetica', sans-serif;
    }
    /* Buton TasarÄ±mÄ± */
    .stButton>button {
        background-color: #d32f2f;
        color: white;
        border-radius: 8px;
        border: none;
        height: 50px;
        width: 100%;
        font-weight: bold;
        font-size: 18px;
    }
    .stButton>button:hover {
        background-color: #b71c1c;
        color: white;
    }
    /* Kart GÃ¶rÃ¼nÃ¼mÃ¼ (Metrics) */
    div[data-testid="stMetric"] {
        background-color: #1e1e1e;
        border: 1px solid #333;
        padding: 15px;
        border-radius: 10px;
        border-left: 5px solid #d32f2f; /* Sol taraf kÄ±rmÄ±zÄ± Ã§izgi */
    }
    div[data-testid="stMetricLabel"] {
        color: #9e9e9e;
    }
    div[data-testid="stMetricValue"] {
        color: #ffffff;
    }
    /* Tablo TasarÄ±mÄ± */
    div[data-testid="stDataFrame"] {
        background-color: #1e1e1e;
    }
    </style>
    """, unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# 2. VERÄ° YÃœKLEME (GOOGLE DRIVE ENTEGRASYONU)
# -----------------------------------------------------------------------------
@st.cache_data
def load_data():
    # Google Drive Linkinden ID'yi alÄ±p CSV indirme linkine Ã§eviriyoruz
    file_id = '1MUbla2YNYsd7sq61F8QL4OBnitw8tsEE'
    url = f'https://docs.google.com/spreadsheets/d/{file_id}/export?format=csv'
    
    try:
        # URL'den okuyoruz
        df = pd.read_csv(url)
    except Exception as e:
        st.error(f"âŒ Veri Google Drive'dan Ã§ekilemedi. Ä°nternet baÄŸlantÄ±nÄ±zÄ± kontrol edin. Hata: {e}")
        return None, None

    # --- Veri Ã–n Ä°ÅŸleme ---
    def normalize_name(text):
        if not isinstance(text, str): return ""
        text = unicodedata.normalize('NFKD', text).encode('ASCII', 'ignore').decode('utf-8')
        return text.lower().strip()

    def work_rate_score(wr):
        if not isinstance(wr, str): return 1
        scores = {'Low': 1, 'Medium': 2, 'High': 3}
        parts = wr.split('/')
        if len(parts) == 2:
            return scores.get(parts[0].strip(), 1) + scores.get(parts[1].strip(), 1)
        return 2

    # Ä°simleri temizle
    if 'Name' in df.columns:
        df['Clean_Name'] = df['Name'].apply(normalize_name)
    
    # Work Rate skorla
    if 'Work Rate' in df.columns:
        df['Work_Rate_Score'] = df['Work Rate'].apply(work_rate_score)
    
    # SayÄ±sal Ã¶zellikler
    features = [
        'Overall', 'Potential', 'Value(Â£)', 'Wage(Â£)', 
        'Age', 'International Reputation', 'Skill Moves', 
        'Weak Foot', 'Special', 'Work_Rate_Score',
        'Height(cm.)', 'Weight(lbs.)'
    ]
    
    # SÃ¼tunlar var mÄ± kontrol et, yoksa hata vermesin diye doldur
    available_features = [f for f in features if f in df.columns]
    
    # Eksik verileri doldur
    df[available_features] = df[available_features].fillna(df[available_features].median())
    
    return df, available_features

# YÃ¼kleme GÃ¶stergesi
with st.spinner('Veriler Google Drive Ã¼zerinden indiriliyor ve iÅŸleniyor...'):
    df, feature_cols = load_data()

if df is None:
    st.stop()

# -----------------------------------------------------------------------------
# 3. MANTIKSAL FONKSÄ°YONLAR
# -----------------------------------------------------------------------------
def get_player_suggestions(df, search_term):
    """Ä°sim dÃ¼zeltme ve tahmin mekanizmasÄ±"""
    clean_term = unicodedata.normalize('NFKD', search_term).encode('ASCII', 'ignore').decode('utf-8').lower().strip()
    
    # Tam EÅŸleÅŸme
    matches = df[df['Clean_Name'].str.contains(clean_term, na=False)]
    if not matches.empty:
        return matches.sort_values(by='Overall', ascending=False).iloc[0], None
    
    # Fuzzy Match (YazÄ±m HatasÄ±)
    all_names = df['Clean_Name'].unique().tolist()
    close_matches = difflib.get_close_matches(clean_term, all_names, n=1, cutoff=0.6)
    
    if close_matches:
        found_name = close_matches[0]
        suggestion = df[df['Clean_Name'] == found_name].iloc[0]
        return suggestion, f"Bunu mu demek istediniz: **{suggestion['Name']}**?"
    
    return None, None

def calculate_similarity(df, target_player, features):
    """KNN Modeli ile benzerleri bulur (MEVKÄ° KÄ°LÄ°TLÄ°)"""
    target_pos = target_player['Position']
    
    # MEVKÄ° FÄ°LTRESÄ°
    pool = df[df['Position'] == target_pos].copy()
    
    if len(pool) < 5:
        return None, "Yetersiz Veri"
    
    # Scale ve Model
    scaler = StandardScaler()
    scaled_pool = scaler.fit_transform(pool[features])
    
    k = min(len(pool), 11)
    knn = NearestNeighbors(n_neighbors=k, metric='euclidean')
    knn.fit(scaled_pool)
    
    # Hedef VektÃ¶r
    target_vector = scaler.transform(target_player[features].to_frame().T)
    distances, indices = knn.kneighbors(target_vector)
    
    recommendations = []
    # indices[0][1:] -> Kendisi hariÃ§ diÄŸerleri
    for i, idx in enumerate(indices[0][1:]):
        neighbor = pool.iloc[idx]
        
        dist = distances[0][i+1]
        score = max(0, 100 - (dist * 5))
        
        # Yorum MantÄ±ÄŸÄ±
        comment = "-"
        if neighbor['Value(Â£)'] < target_player['Value(Â£)'] / 2: comment = "ğŸ’° BÃ¼tÃ§e Dostu"
        elif neighbor['Overall'] > target_player['Overall']: comment = "ğŸ† Daha GÃ¼Ã§lÃ¼"
        elif neighbor['Age'] < target_player['Age'] - 3: comment = "ğŸ‘¶ GenÃ§ Yetenek"
        elif neighbor['Potential'] > target_player['Potential']: comment = "ğŸš€ YÃ¼ksek Potansiyel"
        elif abs(neighbor['Overall'] - target_player['Overall']) < 2: comment = "âš–ï¸ Dengi"

        recommendations.append({
            'Oyuncu': neighbor['Name'],
            'Mevki': neighbor['Position'],
            'TakÄ±m': neighbor['Club'],
            'YaÅŸ': neighbor['Age'],
            'GÃ¼Ã§': neighbor['Overall'],
            'DeÄŸer (Â£)': f"Â£{neighbor['Value(Â£)']:,}",
            'Benzerlik': f"%{score:.1f}",
            'Not': comment
        })
        
    return pd.DataFrame(recommendations), None

# -----------------------------------------------------------------------------
# 4. ARAYÃœZ (UI) TASARIMI
# -----------------------------------------------------------------------------

# BaÅŸlÄ±k BÃ¶lÃ¼mÃ¼
st.title("ğŸ¦ AI FOOTBALL SCOUT")
st.markdown("Yapay zeka destekli, mevkii hassasiyetli oyuncu Ã¶neri sistemi.")
st.divider()

# Arama BÃ¶lÃ¼mÃ¼
col_search, col_btn = st.columns([4, 1])
with col_search:
    player_name = st.text_input("Futbolcu AdÄ± Girin (Ã–rn: Mbappe, Van Dijk, Ozil)", placeholder="Oyuncu adÄ± yazÄ±p Enter'a basÄ±n...")
with col_btn:
    st.write("") 
    st.write("") 
    search_clicked = st.button("ANALÄ°Z ET")

# --- SONUÃ‡ EKRANI ---
if search_clicked or player_name:
    if not player_name:
        st.warning("LÃ¼tfen bir isim girin.")
    else:
        target_player, suggestion_msg = get_player_suggestions(df, player_name)
        
        if target_player is None:
            st.error(f"âŒ '{player_name}' veritabanÄ±nda bulunamadÄ±.")
        else:
            if suggestion_msg:
                st.info(f"âš ï¸ '{player_name}' bulunamadÄ±. {suggestion_msg} analiz ediliyor.")
            
            # --- HEDEF OYUNCU KARTI ---
            st.subheader(f"ğŸ¯ Hedef: {target_player['Name']} ({target_player['Club']})")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1: st.metric("Mevki", target_player['Position'])
            with col2: st.metric("GÃ¼Ã§ (Overall)", target_player['Overall'])
            with col3: st.metric("YaÅŸ", target_player['Age'])
            with col4: st.metric("Piyasa DeÄŸeri", f"Â£{target_player['Value(Â£)']:,}")
            
            # --- ANALÄ°Z VE LÄ°STE ---
            st.markdown("---")
            st.subheader(f"âœ… {target_player['Name']} Yerine Oynayabilecek {target_player['Position']} Alternatifleri")
            
            rec_df, error = calculate_similarity(df, target_player, feature_cols)
            
            if error:
                st.warning(f"âš ï¸ {target_player['Position']} mevkisinde yeterli veri yok.")
            else:
                st.dataframe(
                    rec_df,
                    use_container_width=True,
                    hide_index=True,
                    column_config={
                        "Benzerlik": st.column_config.ProgressColumn(
                            "Benzerlik Skoru",
                            format="%s",
                            min_value=0,
                            max_value=100,
                        ),
                        "Oyuncu": st.column_config.TextColumn("Oyuncu AdÄ±", width="medium"),
                        "Not": st.column_config.TextColumn("Yapay Zeka Yorumu", width="small"),
                    }
                )
